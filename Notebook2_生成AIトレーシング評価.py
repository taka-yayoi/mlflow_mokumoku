# Databricks notebook source
# MAGIC %md
# MAGIC # MLflow ã‚‚ãã‚‚ãä¼š - ç”ŸæˆAIã®ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚° & è©•ä¾¡
# MAGIC
# MAGIC ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€**MLflowã‚’ä½¿ã£ãŸç”ŸæˆAIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã¨è©•ä¾¡**ã‚’å­¦ã³ã¾ã™ã€‚
# MAGIC
# MAGIC ## æœ¬æ—¥ã®æµã‚Œ
# MAGIC 1. **ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—**: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# MAGIC 2. **Part 1**: Tracingã®åŸºæœ¬ã¨Auto-tracing
# MAGIC 3. **Part 2**: GenAI Evaluationã®å®Ÿè·µ
# MAGIC 4. **Part 3**: Custom Judges APIã®ä½¿ç”¨
# MAGIC 5. **Part 4**: æœ¬ç•ªç’°å¢ƒãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
# MAGIC
# MAGIC â€» Databricks Free Edition (Serverless Compute) ã§å‹•ä½œç¢ºèªæ¸ˆã¿ã§ã™
# MAGIC
# MAGIC ğŸ“– å‚è€ƒãƒªãƒ³ã‚¯ï¼š
# MAGIC - [MLflow Tracingï¼ˆè‹±èªï¼‰](https://mlflow.org/docs/latest/llms/tracing/index.html)
# MAGIC - [MLflow LLM Evaluationï¼ˆè‹±èªï¼‰](https://mlflow.org/docs/latest/llms/llm-evaluate/index.html)

# COMMAND ----------

# MAGIC %md
# MAGIC # ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
# MAGIC
# MAGIC å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚
# MAGIC - **MLflow**: å®Ÿé¨“ç®¡ç†ã¨ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°
# MAGIC - **Databricks SDK**: Foundation Model APIã‚¢ã‚¯ã‚»ã‚¹
# MAGIC - **OpenAI**: MLflow OpenAIãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ç”¨
# MAGIC - **Pandas**: ãƒ‡ãƒ¼ã‚¿å‡¦ç†

# COMMAND ----------

# MLflowã¨Databricks SDKã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
%pip install mlflow databricks-sdk openai pandas plotly
dbutils.library.restartPython()

# COMMAND ----------

# MAGIC %md
# MAGIC # Part 1: Tracingã®åŸºæœ¬ã¨Auto-tracing
# MAGIC
# MAGIC **ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ï¼ˆTracingï¼‰**ã¨ã¯ã€LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œéç¨‹ã‚’è¨˜éŒ²ãƒ»å¯è¦–åŒ–ã™ã‚‹æ©Ÿèƒ½ã§ã™ã€‚
# MAGIC
# MAGIC ## ãªãœãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãŒå¿…è¦ï¼Ÿ
# MAGIC
# MAGIC ### ğŸ˜° ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãªã—ã®èª²é¡Œ
# MAGIC - LLMã¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨å¿œç­”ãŒè¦‹ãˆãªã„
# MAGIC - ã‚¨ãƒ©ãƒ¼ã®åŸå› ãŒåˆ†ã‹ã‚‰ãªã„
# MAGIC - ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼ˆé…å»¶ï¼‰ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãŒä¸æ˜
# MAGIC - ã‚³ã‚¹ãƒˆãŒæŠŠæ¡ã§ããªã„
# MAGIC
# MAGIC ### ğŸ˜Š ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã®ãƒ¡ãƒªãƒƒãƒˆ
# MAGIC - ã™ã¹ã¦ã®LLMå‘¼ã³å‡ºã—ãŒè¨˜éŒ²ã•ã‚Œã‚‹
# MAGIC - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨å¿œç­”ãŒå¯è¦–åŒ–ã•ã‚Œã‚‹
# MAGIC - å®Ÿè¡Œæ™‚é–“ã¨ã‚³ã‚¹ãƒˆãŒè¿½è·¡ã§ãã‚‹
# MAGIC - ãƒ‡ãƒãƒƒã‚°ãŒç°¡å˜ã«ãªã‚‹
# MAGIC
# MAGIC ğŸ“– å‚è€ƒãƒªãƒ³ã‚¯ï¼š[MLflow Tracingå…¥é–€ï¼ˆè‹±èªï¼‰](https://mlflow.org/docs/latest/llms/tracing/index.html)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Databricks Foundation Model APIã®è¨­å®š
# MAGIC
# MAGIC Databricks Foundation Model API (FMAPI) ã‚’ä½¿ç”¨ã—ã¦LLMã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚

# COMMAND ----------

from databricks.sdk import WorkspaceClient
from databricks.sdk.service.serving import ChatMessage, ChatMessageRole

# WorkspaceClientã®åˆæœŸåŒ–
w = WorkspaceClient()

def call_fmapi(prompt: str, endpoint: str = "databricks-gpt-oss-20b") -> str:
    """
    Databricks Foundation Model APIã‚’å‘¼ã³å‡ºã™

    Args:
        prompt: LLMã¸ã®å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        endpoint: Foundation Modelã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå

    Returns:
        LLMã‹ã‚‰ã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
    """
    response = w.serving_endpoints.query(
        name=endpoint,
        messages=[
            ChatMessage(role=ChatMessageRole.USER, content=prompt)
        ]
    )
    return response.choices[0].message.content

print("âœ… Foundation Model APIè¨­å®šå®Œäº†")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ã‚·ãƒ³ãƒ—ãƒ«ãªLLMé–¢æ•°ï¼ˆãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãªã—ï¼‰

# COMMAND ----------

def simple_llm_call(question: str) -> str:
    """
    ã‚·ãƒ³ãƒ—ãƒ«ãªLLMå‘¼ã³å‡ºã—ï¼ˆãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãªã—ï¼‰
    """
    # Databricks Foundation Model APIã‚’ä½¿ç”¨
    return call_fmapi(question)

# ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãªã—ã§å®Ÿè¡Œ
print("=== ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãªã—ã®å®Ÿè¡Œ ===")
result = simple_llm_call("MLflowã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ")
print(f"è³ªå•: MLflowã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ")
print(f"å›ç­”: {result}")
print("\nâš ï¸ å®Ÿè¡Œå±¥æ­´ãŒæ®‹ã‚Šã¾ã›ã‚“ï¼")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Auto-tracingã®æœ‰åŠ¹åŒ–
# MAGIC
# MAGIC MLflowã®**Auto-tracing**ã‚’ä½¿ã†ã¨ã€LLMå‘¼ã³å‡ºã—ã‚’è‡ªå‹•çš„ã«ãƒˆãƒ¬ãƒ¼ã‚¹ã§ãã¾ã™ã€‚

# COMMAND ----------

import mlflow
import mlflow.openai

# Auto-tracingã‚’æœ‰åŠ¹åŒ–ï¼ˆOpenAIäº’æ›APIç”¨ï¼‰
mlflow.openai.autolog()

# ãƒˆãƒ¬ãƒ¼ã‚¹ã•ã‚Œã‚‹é–¢æ•°
@mlflow.trace
def traced_llm_call(question: str) -> str:
    """
    ãƒˆãƒ¬ãƒ¼ã‚¹ã•ã‚Œã‚‹LLMå‘¼ã³å‡ºã—
    """
    # Databricks Foundation Model APIã‚’ä½¿ç”¨
    return call_fmapi(question)

# ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚ã‚Šã§å®Ÿè¡Œ
print("=== ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚ã‚Šã®å®Ÿè¡Œ ===")
result = traced_llm_call("ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã¯ã©ã®ã‚ˆã†ã«æ©Ÿèƒ½ã—ã¾ã™ã‹ï¼Ÿ")
print(f"è³ªå•: ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã¯ã©ã®ã‚ˆã†ã«æ©Ÿèƒ½ã—ã¾ã™ã‹ï¼Ÿ")
print(f"å›ç­”: {result}")
print("\nâœ… ãƒˆãƒ¬ãƒ¼ã‚¹ãŒè¨˜éŒ²ã•ã‚Œã¾ã—ãŸï¼")
print("å³å´ã®ã€ŒTracesã€ã‚¿ãƒ–ã‹ã‚‰ç¢ºèªã§ãã¾ã™")

# COMMAND ----------

# MAGIC %md
# MAGIC ## è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°
# MAGIC
# MAGIC RAGï¼ˆRetrieval-Augmented Generationï¼‰ã®ã‚ˆã†ãªè¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã®å‡¦ç†ã‚‚ãƒˆãƒ¬ãƒ¼ã‚¹ã§ãã¾ã™ã€‚

# COMMAND ----------

@mlflow.trace(name="retrieve_documents")
def retrieve_documents(query: str) -> list:
    """
    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰
    """
    # ãƒ¢ãƒƒã‚¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
    docs = [
        "MLflowã¯æ©Ÿæ¢°å­¦ç¿’ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚",
        "MLflowã¯ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€ãƒ¢ãƒ‡ãƒ«ã€ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’æä¾›ã—ã¾ã™ã€‚",
        "ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã¯LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒãƒƒã‚°ã¨æœ€é©åŒ–ã«å½¹ç«‹ã¡ã¾ã™ã€‚"
    ]

    return docs

@mlflow.trace(name="generate_answer")
def generate_answer(query: str, context: list) -> str:
    """
    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ã£ã¦å›ç­”ç”Ÿæˆ
    """
    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ã£ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
    context_text = "\n".join(context)
    prompt = f"""ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å‚è€ƒã«ã€è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:
{context_text}

è³ªå•: {query}

å›ç­”:"""

    # Databricks Foundation Model APIã‚’ä½¿ç”¨
    return call_fmapi(prompt)

@mlflow.trace(name="rag_pipeline")
def rag_pipeline(query: str) -> dict:
    """
    RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“
    """
    # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢
    documents = retrieve_documents(query)

    # ã‚¹ãƒ†ãƒƒãƒ—2: å›ç­”ç”Ÿæˆ
    answer = generate_answer(query, documents)

    return {
        "query": query,
        "documents": documents,
        "answer": answer
    }

# RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
print("=== RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ ===")
result = rag_pipeline("MLflowã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ")
print(f"è³ªå•: {result['query']}")
print(f"å›ç­”: {result['answer']}")
print("\nâœ… å…¨ã‚¹ãƒ†ãƒƒãƒ—ãŒãƒˆãƒ¬ãƒ¼ã‚¹ã•ã‚Œã¾ã—ãŸï¼")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ãƒˆãƒ¬ãƒ¼ã‚¹ã®ç¢ºèª
# MAGIC
# MAGIC ãƒˆãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§å–å¾—ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

# COMMAND ----------

# æœ€æ–°ã®ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å–å¾—
traces = mlflow.search_traces()

if len(traces) > 0:
    print("=== æœ€æ–°ã®ãƒˆãƒ¬ãƒ¼ã‚¹æƒ…å ± ===")
    print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ä»¶æ•°: {len(traces)}")

    # ä¸»è¦ãªæƒ…å ±ã‚’è¡¨ç¤º
    print("\næœ€æ–°ã®ãƒˆãƒ¬ãƒ¼ã‚¹:")
    for idx in range(min(5, len(traces))):
        row = traces.iloc[idx]
        print(f"\n--- ãƒˆãƒ¬ãƒ¼ã‚¹ {idx+1} ---")

        # ä¸€èˆ¬çš„ãªã‚«ãƒ©ãƒ åã‚’è©¦ã™
        for col_name in ['trace_id', 'request_id', 'timestamp_ms', 'execution_time_ms',
                         'status', 'request_metadata', 'tags']:
            if col_name in traces.columns:
                value = row[col_name]
                if value is not None and str(value) != '' and str(value) != 'nan':
                    # è¾æ›¸ã‚„ãƒªã‚¹ãƒˆã¯è¡¨ç¤ºã—ãªã„ï¼ˆè¤‡é›‘ã™ãã‚‹ãŸã‚ï¼‰
                    if not isinstance(value, (dict, list)):
                        if 'time_ms' in col_name and isinstance(value, (int, float)):
                            print(f"  {col_name}: {value:.2f}ms")
                        else:
                            print(f"  {col_name}: {value}")

    print("\nâœ… ãƒˆãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’ç¢ºèªã§ãã¾ã™")
    print("ğŸ“Š ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã¯å³å´ã®ã€ŒTracesã€ã‚¿ãƒ–ã‹ã‚‰ç¢ºèªã—ã¦ãã ã•ã„")
else:
    print("âš ï¸ ãƒˆãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# COMMAND ----------

# MAGIC %md
# MAGIC # Part 2: GenAI Evaluationã®å®Ÿè·µ
# MAGIC
# MAGIC LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å“è³ªã‚’è©•ä¾¡ã—ã¾ã™ã€‚
# MAGIC
# MAGIC ## è©•ä¾¡ã®é‡è¦æ€§
# MAGIC
# MAGIC LLMã®å‡ºåŠ›ã¯ç¢ºç‡çš„ãªã®ã§ã€ä»¥ä¸‹ã‚’è©•ä¾¡ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š
# MAGIC - **æ­£ç¢ºæ€§ï¼ˆCorrectnessï¼‰**: å›ç­”ãŒæ­£ã—ã„ã‹
# MAGIC - **é–¢é€£æ€§ï¼ˆRelevanceï¼‰**: è³ªå•ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹
# MAGIC - **å®‰å…¨æ€§ï¼ˆSafetyï¼‰**: æœ‰å®³ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å«ã¾ãªã„ã‹
# MAGIC - **å¹»è¦šï¼ˆGroundednessï¼‰**: äº‹å®Ÿã¨ç•°ãªã‚‹æƒ…å ±ã‚’ç”Ÿæˆã—ã¦ã„ãªã„ã‹
# MAGIC
# MAGIC ## äº‹å‰æ§‹ç¯‰ã•ã‚ŒãŸJudge
# MAGIC
# MAGIC MLflowã¯ä»¥ä¸‹ã®äº‹å‰æ§‹ç¯‰ã•ã‚ŒãŸJudgeã‚’æä¾›ã—ã¦ã„ã¾ã™ï¼š
# MAGIC - `RelevanceToQuery`: è³ªå•ã¸ã®é–¢é€£æ€§
# MAGIC - `Correctness`: æ­£ç¢ºæ€§ï¼ˆã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ã¨ã®æ¯”è¼ƒï¼‰
# MAGIC - `Safety`: å®‰å…¨æ€§ï¼ˆæœ‰å®³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ¤œå‡ºï¼‰
# MAGIC - `RetrievalGroundedness`: å¹»è¦šã®æ¤œå‡º
# MAGIC - `Guidelines`: ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³æº–æ‹ 
# MAGIC
# MAGIC ğŸ“– å‚è€ƒãƒªãƒ³ã‚¯ï¼š
# MAGIC - [äº‹å‰æ§‹ç¯‰ã•ã‚ŒãŸJudgesï¼ˆæ—¥æœ¬èªï¼‰](https://docs.databricks.com/aws/ja/mlflow3/genai/eval-monitor/concepts/judges/pre-built-judges-scorers)
# MAGIC - [LLM Evaluation Guideï¼ˆè‹±èªï¼‰](https://mlflow.org/docs/latest/llms/llm-evaluate/index.html)

# COMMAND ----------

# MAGIC %md
# MAGIC ## è©•ä¾¡ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™

# COMMAND ----------

import pandas as pd

# è©•ä¾¡ç”¨ã®QAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
eval_data = pd.DataFrame({
    "question": [
        "MLflowã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "MLflowã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ©Ÿèƒ½ã¯ã©ã®ã‚ˆã†ã«å‹•ä½œã—ã¾ã™ã‹ï¼Ÿ",
        "ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "MLflowã‚’ä½¿ã£ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹æ–¹æ³•ã¯ï¼Ÿ",
        "MLflow Projectsã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ"
    ],
    "ground_truth": [
        "MLflowã¯æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«å…¨ä½“ã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚",
        "MLflow Trackingã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€MLã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹éš›ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ãƒ­ã‚°ã§ãã¾ã™ã€‚",
        "ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã®é›†ä¸­å‹ãƒ¢ãƒ‡ãƒ«ã‚¹ãƒˆã‚¢ã§ã™ã€‚",
        "MLflow Modelsã¯æ¨™æº–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã€ã•ã¾ã–ã¾ãªãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã¾ã™ã€‚",
        "MLflow Projectsã¯ã€å†åˆ©ç”¨å¯èƒ½ã§å†ç¾å¯èƒ½ãªå½¢å¼ã§MLã‚³ãƒ¼ãƒ‰ã‚’ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åŒ–ã—ã¾ã™ã€‚"
    ]
})

print("=== è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ===")
display(eval_data)

# COMMAND ----------

# MAGIC %md
# MAGIC ## ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’å–å¾—

# COMMAND ----------

def qa_model(question: str) -> str:
    """
    è³ªå•å¿œç­”ãƒ¢ãƒ‡ãƒ«
    """
    # Databricks Foundation Model APIã‚’ä½¿ç”¨
    return call_fmapi(question)

# äºˆæ¸¬ã‚’ç”Ÿæˆ
eval_data["prediction"] = eval_data["question"].apply(qa_model)

print("=== äºˆæ¸¬çµæœ ===")
display(eval_data[["question", "prediction"]])

# COMMAND ----------

# MAGIC %md
# MAGIC ## äº‹å‰æ§‹ç¯‰ã•ã‚ŒãŸJudgeã‚’ä½¿ã£ãŸè©•ä¾¡
# MAGIC
# MAGIC MLflowã®äº‹å‰æ§‹ç¯‰ã•ã‚ŒãŸJudgeï¼ˆè©•ä¾¡è€…ï¼‰ã‚’ä½¿ã„ã¾ã™ã€‚

# COMMAND ----------

from mlflow.genai.scorers import RelevanceToQuery, Correctness, Safety

# è©•ä¾¡ç”¨ã®predicté–¢æ•°ã‚’ä½œæˆ
def predict_fn(inputs):
    """
    è©•ä¾¡ç”¨ã®predicté–¢æ•°
    inputs: 'question'ã‚«ãƒ©ãƒ ã‚’æŒã¤DataFrame
    returns: äºˆæ¸¬çµæœã®ãƒªã‚¹ãƒˆ
    """
    results = []
    for question in inputs['question']:
        prediction = qa_model(question)
        results.append(prediction)
    return results

# è©•ä¾¡ã®å®Ÿè¡Œ
with mlflow.start_run(run_name="QA Model Evaluation with Judges"):

    # Judgeï¼ˆè©•ä¾¡è€…ï¼‰ã‚’å®šç¾©
    judges = [
        RelevanceToQuery(),  # è³ªå•ã¸ã®é–¢é€£æ€§
        Correctness(),       # æ­£ç¢ºæ€§ï¼ˆã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ã¨æ¯”è¼ƒï¼‰
        Safety()             # å®‰å…¨æ€§ï¼ˆæœ‰å®³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ¤œå‡ºï¼‰
    ]

    # mlflow.genai.evaluateã§è©•ä¾¡
    eval_results = mlflow.genai.evaluate(
        data=eval_data,
        predict_fn=predict_fn,
        scorers=judges
    )

    print("=== è©•ä¾¡çµæœ ===")
    print(f"\nè©•ä¾¡ã‚¹ã‚³ã‚¢:")
    for metric_name, metric_value in eval_results.metrics.items():
        print(f"  {metric_name}: {metric_value:.3f}")

    print("\nâœ… è©•ä¾¡çµæœãŒMLflowã«è¨˜éŒ²ã•ã‚Œã¾ã—ãŸï¼")
    print("ğŸ“Š è©³ç´°ãªè©•ä¾¡çµæœã¯å³å´ã®ã€ŒExperimentsã€ã‚¿ãƒ–ã‹ã‚‰ç¢ºèªã§ãã¾ã™")

# COMMAND ----------

# MAGIC %md
# MAGIC # Part 3: Custom Judges APIã®ä½¿ç”¨
# MAGIC
# MAGIC **Judge**ã¯ã€LLMã®å‡ºåŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®è©•ä¾¡è€…ã§ã™ã€‚
# MAGIC
# MAGIC ## Judgeã®ç¨®é¡
# MAGIC - **äº‹å‰æ§‹ç¯‰ã•ã‚ŒãŸJudges**: MLflowãŒæä¾›ã™ã‚‹æ¨™æº–çš„ãªè©•ä¾¡è€…ï¼ˆPart 2ã§ä½¿ç”¨ï¼‰
# MAGIC - **ã‚«ã‚¹ã‚¿ãƒ Scorer**: ç‹¬è‡ªã®è©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
# MAGIC
# MAGIC ğŸ“– å‚è€ƒãƒªãƒ³ã‚¯ï¼š
# MAGIC - [äº‹å‰æ§‹ç¯‰ã•ã‚ŒãŸJudgesï¼ˆæ—¥æœ¬èªï¼‰](https://docs.databricks.com/aws/ja/mlflow3/genai/eval-monitor/concepts/judges/pre-built-judges-scorers)
# MAGIC - [ã‚«ã‚¹ã‚¿ãƒ Scorerï¼ˆè‹±èªï¼‰](https://mlflow.org/docs/latest/llms/llm-evaluate/index.html#custom-llm-evaluation-metrics)

# COMMAND ----------

# MAGIC %md
# MAGIC ## ãã®ä»–ã®äº‹å‰æ§‹ç¯‰ã•ã‚ŒãŸJudgeã®ä½¿ç”¨

# COMMAND ----------

from mlflow.genai.scorers import RetrievalGroundedness, Guidelines

# Guidelines Judgeï¼ˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³æº–æ‹ ï¼‰ã®ä½œæˆ
guidelines = Guidelines(
    guidelines="""
    è‰¯ã„å›ç­”ã®åŸºæº–:
    1. ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„
    2. å°‚é–€ç”¨èªã‚’é©åˆ‡ã«ä½¿ç”¨
    3. å…·ä½“ä¾‹ã‚’å«ã‚€
    """
)

# è©•ä¾¡ã®å®Ÿè¡Œ
with mlflow.start_run(run_name="Advanced Judges Evaluation"):

    # Judgeï¼ˆè©•ä¾¡è€…ï¼‰ã‚’å®šç¾©
    advanced_judges = [
        RetrievalGroundedness(),  # å¹»è¦šã®æ¤œå‡º
        guidelines                # ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³æº–æ‹ 
    ]

    # mlflow.genai.evaluateã§è©•ä¾¡
    eval_results = mlflow.genai.evaluate(
        data=eval_data,
        predict_fn=predict_fn,
        scorers=advanced_judges
    )

    print("=== è¿½åŠ è©•ä¾¡çµæœ ===")
    print(f"\nè©•ä¾¡ã‚¹ã‚³ã‚¢:")
    for metric_name, metric_value in eval_results.metrics.items():
        print(f"  {metric_name}: {metric_value:.3f}")

    print("\nâœ… è¿½åŠ è©•ä¾¡çµæœãŒMLflowã«è¨˜éŒ²ã•ã‚Œã¾ã—ãŸï¼")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ã‚«ã‚¹ã‚¿ãƒ Scorerã®ä½œæˆ
# MAGIC
# MAGIC ç‹¬è‡ªã®è©•ä¾¡åŸºæº–ã‚’å®Ÿè£…ã§ãã¾ã™ã€‚

# COMMAND ----------

from mlflow.genai.scorers import make_genai_metric_scorer

# ã‚«ã‚¹ã‚¿ãƒ Scorer: å›ç­”ã®é•·ã•ã‚’è©•ä¾¡
def length_scorer(inputs, outputs):
    """
    å›ç­”ã®é•·ã•ãŒé©åˆ‡ã‹ã‚’è©•ä¾¡
    """
    scores = []
    for output in outputs:
        if isinstance(output, dict):
            text = output.get('text', output.get('content', str(output)))
        else:
            text = str(output)

        length = len(text)
        # 50-300æ–‡å­—ãŒé©åˆ‡ã¨ä»®å®š
        if 50 <= length <= 300:
            score = 1.0
        elif length < 50:
            score = 0.5  # çŸ­ã™ãã‚‹
        else:
            score = 0.7  # é•·ã™ãã‚‹ãŒè¨±å®¹
        scores.append(score)

    return scores

# ã‚«ã‚¹ã‚¿ãƒ Scorer: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å­˜åœ¨ã‚’ç¢ºèª
def keyword_scorer(inputs, outputs):
    """
    é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡
    """
    important_keywords = ["MLflow", "ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°", "ãƒ¢ãƒ‡ãƒ«", "ãƒ¬ã‚¸ã‚¹ãƒˆãƒª", "ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ "]
    scores = []

    for output in outputs:
        if isinstance(output, dict):
            text = output.get('text', output.get('content', str(output)))
        else:
            text = str(output)

        keyword_count = sum(1 for kw in important_keywords if kw in text)
        score = min(keyword_count / 2.0, 1.0)  # æœ€å¤§1.0
        scores.append(score)

    return scores

print("âœ… ã‚«ã‚¹ã‚¿ãƒ Scorerã‚’2ã¤ä½œæˆã—ã¾ã—ãŸ")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ã‚«ã‚¹ã‚¿ãƒ Scorerã§è©•ä¾¡

# COMMAND ----------

with mlflow.start_run(run_name="Custom Scorer Evaluation"):

    # ã‚«ã‚¹ã‚¿ãƒ Scorerã§è©•ä¾¡
    custom_scorers = [
        length_scorer,
        keyword_scorer
    ]

    eval_results = mlflow.genai.evaluate(
        data=eval_data,
        predict_fn=predict_fn,
        scorers=custom_scorers
    )

    print("=== ã‚«ã‚¹ã‚¿ãƒ Scorerè©•ä¾¡çµæœ ===")
    print(f"\nè©•ä¾¡ã‚¹ã‚³ã‚¢:")
    for metric_name, metric_value in eval_results.metrics.items():
        print(f"  {metric_name}: {metric_value:.3f}")

    print("\nâœ… ã‚«ã‚¹ã‚¿ãƒ Scorerè©•ä¾¡çµæœãŒMLflowã«è¨˜éŒ²ã•ã‚Œã¾ã—ãŸï¼")

# COMMAND ----------

# MAGIC %md
# MAGIC # Part 4: æœ¬ç•ªç’°å¢ƒãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
# MAGIC
# MAGIC æœ¬ç•ªç’°å¢ƒã§ã®LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç¶™ç¶šçš„ã«ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚
# MAGIC
# MAGIC ## ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã®é‡è¦æ€§
# MAGIC
# MAGIC ### ãªãœãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãŒå¿…è¦ï¼Ÿ
# MAGIC - **å“è³ªã®ä½ä¸‹æ¤œå‡º**: ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›å“è³ªãŒä½ä¸‹ã—ã¦ã„ãªã„ã‹
# MAGIC - **ã‚³ã‚¹ãƒˆç®¡ç†**: ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã¨ã‚³ã‚¹ãƒˆã®è¿½è·¡
# MAGIC - **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¨å¯ç”¨æ€§ã®ç›£è¦–
# MAGIC - **ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**: å®Ÿéš›ã®ä½¿ç”¨çŠ¶æ³ã®æŠŠæ¡
# MAGIC
# MAGIC ğŸ“– å‚è€ƒãƒªãƒ³ã‚¯ï¼š[MLflow Deploymentï¼ˆè‹±èªï¼‰](https://mlflow.org/docs/latest/deployment/index.html)

# COMMAND ----------

# MAGIC %md
# MAGIC ## æœ¬ç•ªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

# COMMAND ----------

import random
from datetime import datetime, timedelta

# æœ¬ç•ªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
def simulate_production_traffic(num_requests=20):
    """
    æœ¬ç•ªç’°å¢ƒã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    """
    questions = [
        "MLflowã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "MLflowã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã¯ã©ã®ã‚ˆã†ã«æ©Ÿèƒ½ã—ã¾ã™ã‹ï¼Ÿ",
        "ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹æ–¹æ³•ã¯ï¼Ÿ",
        "MLflow Projectsã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "Pythonã§MLflowã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã¯ï¼Ÿ",
        "MLflowãƒ¢ãƒ‡ãƒ«ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
    ]

    traffic_data = []

    for i in range(num_requests):
        question = random.choice(questions)

        # ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’è¨˜éŒ²
        with mlflow.start_run(run_name=f"production_request_{i}"):
            start_time = time.time()

            # äºˆæ¸¬ã‚’å®Ÿè¡Œ
            prediction = qa_model(question)

            latency = time.time() - start_time
            token_count = len(prediction.split())

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²
            mlflow.log_param("question", question)
            mlflow.log_metric("latency_ms", latency * 1000)
            mlflow.log_metric("token_count", token_count)
            mlflow.log_metric("timestamp", time.time())

            # ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¹ã‚³ã‚¢ï¼ˆ1-5ï¼‰
            feedback_score = random.randint(3, 5)
            mlflow.log_metric("user_feedback", feedback_score)

            traffic_data.append({
                "request_id": i,
                "question": question,
                "prediction": prediction,
                "latency_ms": latency * 1000,
                "token_count": token_count,
                "user_feedback": feedback_score,
                "timestamp": datetime.now() - timedelta(minutes=num_requests - i)
            })

    return pd.DataFrame(traffic_data)

# ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
print("=== æœ¬ç•ªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆä¸­ ===")
production_data = simulate_production_traffic(20)
print(f"âœ… {len(production_data)}ä»¶ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è¨˜éŒ²ã—ã¾ã—ãŸ")

display(production_data.head())

# COMMAND ----------

# MAGIC %md
# MAGIC ## ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

# COMMAND ----------

from plotly.subplots import make_subplots
import plotly.graph_objects as go

# ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆ
fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=(
        'ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®æ¨ç§»',
        'ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡',
        'ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯',
        'ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã®æ¨ç§»'
    )
)

# ã‚°ãƒ©ãƒ•1: ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®æ¨ç§»
fig.add_trace(
    go.Scatter(
        x=production_data['request_id'],
        y=production_data['latency_ms'],
        mode='lines+markers',
        name='ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·',
        line=dict(color='blue')
    ),
    row=1, col=1
)

# ã‚°ãƒ©ãƒ•2: ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
fig.add_trace(
    go.Histogram(
        x=production_data['token_count'],
        name='ãƒˆãƒ¼ã‚¯ãƒ³æ•°',
        marker_color='green'
    ),
    row=1, col=2
)

# ã‚°ãƒ©ãƒ•3: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®åˆ†å¸ƒ
feedback_counts = production_data['user_feedback'].value_counts().sort_index()
fig.add_trace(
    go.Bar(
        x=feedback_counts.index,
        y=feedback_counts.values,
        name='ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯',
        marker_color='orange'
    ),
    row=2, col=1
)

# ã‚°ãƒ©ãƒ•4: ç´¯ç©ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°
fig.add_trace(
    go.Scatter(
        x=production_data['request_id'],
        y=range(1, len(production_data) + 1),
        mode='lines',
        name='ç´¯ç©ãƒªã‚¯ã‚¨ã‚¹ãƒˆ',
        line=dict(color='purple')
    ),
    row=2, col=2
)

# ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
fig.update_xaxes(title_text="ãƒªã‚¯ã‚¨ã‚¹ãƒˆID", row=1, col=1)
fig.update_yaxes(title_text="ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms)", row=1, col=1)

fig.update_xaxes(title_text="ãƒˆãƒ¼ã‚¯ãƒ³æ•°", row=1, col=2)
fig.update_yaxes(title_text="é »åº¦", row=1, col=2)

fig.update_xaxes(title_text="è©•ä¾¡ã‚¹ã‚³ã‚¢", row=2, col=1)
fig.update_yaxes(title_text="ä»¶æ•°", row=2, col=1)

fig.update_xaxes(title_text="ãƒªã‚¯ã‚¨ã‚¹ãƒˆID", row=2, col=2)
fig.update_yaxes(title_text="ç´¯ç©ä»¶æ•°", row=2, col=2)

fig.update_layout(
    height=600,
    showlegend=False,
    title_text="æœ¬ç•ªç’°å¢ƒãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"
)

fig.show()

# COMMAND ----------

# MAGIC %md
# MAGIC ## ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°çµ±è¨ˆ

# COMMAND ----------

# çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
stats = {
    "ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°": len(production_data),
    "å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms)": production_data['latency_ms'].mean(),
    "æœ€å¤§ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms)": production_data['latency_ms'].max(),
    "å¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°": production_data['token_count'].mean(),
    "ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°": production_data['token_count'].sum(),
    "å¹³å‡ãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡": production_data['user_feedback'].mean(),
}

print("=== æœ¬ç•ªç’°å¢ƒçµ±è¨ˆ ===")
for key, value in stats.items():
    if isinstance(value, float):
        print(f"{key}: {value:.2f}")
    else:
        print(f"{key}: {value}")

# MLflowã«è¨˜éŒ²
with mlflow.start_run(run_name="Production Monitoring Summary"):
    for key, value in stats.items():
        mlflow.log_metric(key.replace(" ", "_").replace("(", "").replace(")", ""), value)

    mlflow.log_table(production_data, artifact_file="production_traffic.json")

print("\nâœ… ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’MLflowã«è¨˜éŒ²ã—ã¾ã—ãŸ")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶ã®è¨­å®š

# COMMAND ----------

# ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯
def check_alerts(data):
    """
    ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯
    """
    alerts = []

    # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆ1000msè¶…éï¼‰
    high_latency = data[data['latency_ms'] > 1000]
    if len(high_latency) > 0:
        alerts.append(f"âš ï¸ é«˜ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ¤œå‡º: {len(high_latency)}ä»¶ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒ1ç§’ä»¥ä¸Š")

    # ä½è©•ä¾¡ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆã‚¹ã‚³ã‚¢3ä»¥ä¸‹ï¼‰
    low_feedback = data[data['user_feedback'] <= 3]
    if len(low_feedback) > len(data) * 0.3:  # 30%ä»¥ä¸Š
        alerts.append(f"âš ï¸ ä½è©•ä¾¡ãŒå¤šã„: {len(low_feedback)}ä»¶ï¼ˆ{len(low_feedback)/len(data)*100:.1f}%ï¼‰")

    # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚¢ãƒ©ãƒ¼ãƒˆ
    avg_tokens = data['token_count'].mean()
    if avg_tokens > 50:
        alerts.append(f"âš ï¸ ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ãŒå¤šã„: å¹³å‡{avg_tokens:.1f}ãƒˆãƒ¼ã‚¯ãƒ³")

    return alerts

# ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
alerts = check_alerts(production_data)

print("=== ã‚¢ãƒ©ãƒ¼ãƒˆçŠ¶æ³ ===")
if alerts:
    for alert in alerts:
        print(alert)
else:
    print("âœ… ã™ã¹ã¦æ­£å¸¸ã§ã™")

# COMMAND ----------

# MAGIC %md
# MAGIC # ã¾ã¨ã‚ï¼šç”ŸæˆAIãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚° & è©•ä¾¡ã®ãƒ¡ãƒªãƒƒãƒˆ
# MAGIC
# MAGIC ## ä»Šæ—¥ä½“é¨“ã—ãŸã“ã¨
# MAGIC
# MAGIC ### âœ… ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°
# MAGIC - LLMå‘¼ã³å‡ºã—ã®è‡ªå‹•è¨˜éŒ²
# MAGIC - è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã®å‡¦ç†ã‚’å¯è¦–åŒ–
# MAGIC - ãƒ‡ãƒãƒƒã‚°ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ãŒå®¹æ˜“
# MAGIC
# MAGIC ### âœ… è©•ä¾¡ï¼ˆEvaluationï¼‰
# MAGIC - çµ„ã¿è¾¼ã¿ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§å“è³ªæ¸¬å®š
# MAGIC - ã‚«ã‚¹ã‚¿ãƒ Judgeã§ç‹¬è‡ªã®è©•ä¾¡åŸºæº–ã‚’å®Ÿè£…
# MAGIC - ç¶™ç¶šçš„ãªå“è³ªãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
# MAGIC
# MAGIC ### âœ… æœ¬ç•ªãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
# MAGIC - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡
# MAGIC - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®åé›†
# MAGIC - ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šã§å•é¡Œã‚’æ—©æœŸç™ºè¦‹
# MAGIC
# MAGIC ## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
# MAGIC
# MAGIC - **å®Ÿéš›ã®LLM APIã¨ã®çµ±åˆ**: OpenAIã€Anthropicãªã©
# MAGIC - **ã‚ˆã‚Šé«˜åº¦ãªè©•ä¾¡**: BLEUã€ROUGEã€BERTScoreãªã©
# MAGIC - **A/Bãƒ†ã‚¹ãƒˆ**: è¤‡æ•°ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒ
# MAGIC - **ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³å±•é–‹**: MLflow Deploymentã®æ´»ç”¨
# MAGIC
# MAGIC ğŸ“– å‚è€ƒãƒªãƒ³ã‚¯ï¼š
# MAGIC - [MLflow LLMsã‚¬ã‚¤ãƒ‰ï¼ˆè‹±èªï¼‰](https://mlflow.org/docs/latest/llms/index.html)
# MAGIC - [Databricks LLMsã‚¬ã‚¤ãƒ‰ï¼ˆæ—¥æœ¬èªï¼‰](https://docs.databricks.com/ja/generative-ai/index.html)

# COMMAND ----------

# MAGIC %md
# MAGIC # è£œè¶³ï¼šã‚ˆãã‚ã‚‹è³ªå•
# MAGIC
# MAGIC **Q1: ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã¯ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ï¼Ÿ**
# MAGIC
# MAGIC A: ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°è‡ªä½“ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã¯æœ€å°é™ã§ã™ã€‚LLMå‘¼ã³å‡ºã—ã®ã‚³ã‚¹ãƒˆãŒä¸»ãªéƒ¨åˆ†ã§ã™ã€‚
# MAGIC
# MAGIC **Q2: ã‚«ã‚¹ã‚¿ãƒ Judgeã«LLMã‚’ä½¿ãˆã‚‹ï¼Ÿ**
# MAGIC
# MAGIC A: ã¯ã„ï¼å®Ÿéš›ã«ã¯åˆ¥ã®LLMã‚’ä½¿ã£ã¦å‡ºåŠ›ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ãŒä¸€èˆ¬çš„ã§ã™ï¼ˆLLM-as-a-Judgeï¼‰ã€‚
# MAGIC
# MAGIC **Q3: æœ¬ç•ªç’°å¢ƒã§ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’ç„¡åŠ¹åŒ–ã™ã¹ãï¼Ÿ**
# MAGIC
# MAGIC A: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆä¸€éƒ¨ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ã¿ãƒˆãƒ¬ãƒ¼ã‚¹ï¼‰ã‚’ä½¿ãˆã°ã€æœ¬ç•ªã§ã‚‚æœ‰åŠ¹ã«ã§ãã¾ã™ã€‚
# MAGIC
# MAGIC **Q4: è¤‡æ•°ã®LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«å¯¾å¿œã—ã¦ã„ã‚‹ï¼Ÿ**
# MAGIC
# MAGIC A: ã¯ã„ï¼OpenAIã€Anthropicã€HuggingFaceã€Azure OpenAIãªã©å¤šæ•°å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚
# MAGIC
# MAGIC **Q5: ã‚‚ã£ã¨è©³ã—ãå­¦ã¶ã«ã¯ï¼Ÿ**
# MAGIC
# MAGIC A:
# MAGIC - [MLflow LLMså…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆè‹±èªï¼‰](https://mlflow.org/docs/latest/llms/index.html)
# MAGIC - [Databricksç”ŸæˆAIã‚¬ã‚¤ãƒ‰ï¼ˆæ—¥æœ¬èªï¼‰](https://docs.databricks.com/ja/generative-ai/index.html)
# MAGIC - [MLflow Tracingè©³ç´°ï¼ˆè‹±èªï¼‰](https://mlflow.org/docs/latest/llms/tracing/index.html)

# COMMAND ----------

# MAGIC %md
# MAGIC # ğŸ‰ ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼
# MAGIC
# MAGIC ç”ŸæˆAIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã¨è©•ä¾¡ã®åŸºæœ¬ã‚’å­¦ã³ã¾ã—ãŸã€‚
# MAGIC
# MAGIC ã“ã‚Œã‚‰ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’ä½¿ã£ã¦ã€é«˜å“è³ªãªLLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã—ã¦ãã ã•ã„ï¼
